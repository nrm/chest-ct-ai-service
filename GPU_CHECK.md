# üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –≤ RadiAssist

## –ë—ã—Å—Ç—Ä—ã–µ —Å–ø–æ—Å–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∫–∏

### 1. **–ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ API (–µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—â–µ–Ω)**
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ GPU
curl -s http://localhost:8000/gpu-status | python3 -m json.tool

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞
curl -s http://localhost:8000/health
```

### 2. **–ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ —Å–∫—Ä–∏–ø—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏**
```bash
# –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞
python3 check_gpu.py
```

### 3. **–ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤ –∑–∞–ø—É—Å–∫–∞**
```bash
# –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤ —Å GPU –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π
docker compose -f docker-compose.new.yml logs backend | grep -E "(GPU|nvidia|CUDA|PyTorch)"

# –ü—Ä–æ—Å–º–æ—Ç—Ä –≤—Å–µ—Ö –ª–æ–≥–æ–≤ –∑–∞–ø—É—Å–∫–∞
docker compose -f docker-compose.new.yml logs backend | head -100
```

### 4. **–ü—Ä–æ–≤–µ—Ä–∫–∞ Docker GPU –ø—Ä–æ–±—Ä–æ—Å–∞**
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –≤–∏–¥–∏—Ç GPU
docker exec -it $(docker ps -q --filter "name=backend") nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
docker exec -it $(docker ps -q --filter "name=backend") env | grep -E "(CUDA|NVIDIA)"
```

## üöÄ –ó–∞–ø—É—Å–∫ —Å GPU

### –°–ø–æ—Å–æ–± 1: –ß–µ—Ä–µ–∑ run-gpu.sh
```bash
./run-gpu.sh
```

### –°–ø–æ—Å–æ–± 2: –ß–µ—Ä–µ–∑ docker-compose —Å GPU
```bash
# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
docker compose -f docker-compose.new.yml down

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å GPU –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
docker compose -f docker-compose.new.yml -f docker-compose.gpu.yml up --build -d

# –ò–ª–∏ —Å legacy GPU –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
docker compose -f docker-compose.new.yml -f docker-compose.gpu-legacy.yml up --build -d
```

### –°–ø–æ—Å–æ–± 3: –ü—Ä—è–º–æ–π –∑–∞–ø—É—Å–∫ —Å GPU
```bash
# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
docker compose -f docker-compose.new.yml down

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å GPU
docker run --gpus all -p 8000:8000 -v $(pwd)/data:/app/data -v $(pwd)/logs:/app/logs radiassist-api:latest
```

## üîß –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º

### –ï—Å–ª–∏ GPU –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:

1. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ NVIDIA –¥—Ä–∞–π–≤–µ—Ä—ã:**
   ```bash
   nvidia-smi
   ```

2. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ nvidia-docker2:**
   ```bash
   docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
   ```

3. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ Docker Compose –≤–µ—Ä—Å–∏—é:**
   ```bash
   docker compose version
   ```

4. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞:**
   ```bash
   ls -la /dev/nvidia*
   ```

### –û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–π —Ä–∞–±–æ—Ç–µ GPU:

```
üîç GPU Diagnostics at startup:
‚úÖ nvidia-smi command successful:
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
+-----------------------------------------------------------------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce RTX 3080    Off  | 00000000:01:00.0 Off |                  N/A |
|  0%   42C    P8    15W / 320W |      0MiB / 10240MiB |      0%      Default |
|                               |                      |                  N/A |
+-----------------------------------------------------------------------------+

üî• PyTorch CUDA available: True
üî• PyTorch CUDA device count: 1
üî• PyTorch current device: 0
üî• PyTorch device name: GeForce RTX 3080
```

## ‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –° GPU:
- –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 10-60 —Å–µ–∫—É–Ω–¥
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU: 80-95%
- –ü–∞–º—è—Ç—å GPU: 2-8 GB

### –ë–µ–∑ GPU (CPU only):
- –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 5-30 –º–∏–Ω—É—Ç
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU: 100%
- –ü–∞–º—è—Ç—å RAM: 4-16 GB

## üÜò –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–æ–≥–∞–µ—Ç

1. –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É
2. –û–±–Ω–æ–≤–∏—Ç–µ NVIDIA –¥—Ä–∞–π–≤–µ—Ä—ã
3. –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ nvidia-docker2
4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π CUDA –∏ PyTorch
5. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å `--privileged` —Ñ–ª–∞–≥–æ–º

```bash
docker run --privileged --gpus all -p 8000:8000 radiassist-api:latest
```
