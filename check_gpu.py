#!/usr/bin/env python3
"""
GPU Check Script for RadiAssist
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU –∏ –≤—ã–≤–æ–¥–∏—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
"""

import os
import sys
import subprocess
import json
from pathlib import Path

def check_nvidia_smi():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å nvidia-smi"""
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ nvidia-smi...")
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("‚úÖ nvidia-smi –¥–æ—Å—Ç—É–ø–µ–Ω")
            print("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU:")
            print(result.stdout)
            return True
        else:
            print("‚ùå nvidia-smi –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            print(f"–û—à–∏–±–∫–∞: {result.stderr}")
            return False
    except subprocess.TimeoutExpired:
        print("‚è∞ nvidia-smi –∫–æ–º–∞–Ω–¥–∞ –ø—Ä–µ–≤—ã—Å–∏–ª–∞ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è")
        return False
    except FileNotFoundError:
        print("‚ùå nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ PATH")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ nvidia-smi: {e}")
        return False

def check_pytorch_cuda():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å PyTorch CUDA"""
    print("\nüî• –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch CUDA...")
    try:
        import torch
        print(f"‚úÖ PyTorch —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {torch.__version__}")
        
        if torch.cuda.is_available():
            print("‚úÖ PyTorch CUDA –¥–æ—Å—Ç—É–ø–µ–Ω")
            print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {torch.cuda.device_count()}")
            print(f"üìä –¢–µ–∫—É—â–µ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {torch.cuda.current_device()}")
            print(f"üìä –ò–º—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞: {torch.cuda.get_device_name()}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                print(f"üìä GPU {i}: {props.name}")
                print(f"   - –ü–∞–º—è—Ç—å: {props.total_memory / 1024**3:.1f} GB")
                print(f"   - Compute Capability: {props.major}.{props.minor}")
            
            return True
        else:
            print("‚ùå PyTorch CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            print("–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
            print("- CUDA –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            print("- PyTorch —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω –±–µ–∑ CUDA")
            print("- GPU –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
            return False
    except ImportError:
        print("‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ PyTorch CUDA: {e}")
        return False

def check_environment_variables():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    print("\nüåç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    
    env_vars = [
        'CUDA_VISIBLE_DEVICES',
        'NVIDIA_VISIBLE_DEVICES', 
        'NVIDIA_DRIVER_CAPABILITIES'
    ]
    
    for var in env_vars:
        value = os.getenv(var, '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞')
        print(f"üìä {var}: {value}")

def check_docker_gpu():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∑–∞–ø—É—â–µ–Ω –ª–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å GPU –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π"""
    print("\nüêã –ü—Ä–æ–≤–µ—Ä–∫–∞ Docker GPU...")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ–∞–π–ª—ã NVIDIA –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
        nvidia_files = [
            '/dev/nvidia0',
            '/dev/nvidiactl',
            '/dev/nvidia-modeset',
            '/dev/nvidia-uvm'
        ]
        
        for file_path in nvidia_files:
            if os.path.exists(file_path):
                print(f"‚úÖ {file_path} –Ω–∞–π–¥–µ–Ω")
            else:
                print(f"‚ùå {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è Docker
        if os.getenv('NVIDIA_VISIBLE_DEVICES'):
            print("‚úÖ NVIDIA_VISIBLE_DEVICES —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
        else:
            print("‚ùå NVIDIA_VISIBLE_DEVICES –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ Docker GPU: {e}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ RadiAssist GPU Diagnostic Tool")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º nvidia-smi
    nvidia_available = check_nvidia_smi()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º PyTorch CUDA
    pytorch_cuda_available = check_pytorch_cuda()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    check_environment_variables()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Docker GPU
    check_docker_gpu()
    
    print("\n" + "=" * 50)
    print("üìã –ò–¢–û–ì–û–í–´–ô –°–¢–ê–¢–£–°:")
    
    if nvidia_available and pytorch_cuda_available:
        print("‚úÖ GPU –ø–æ–ª–Ω–æ—Å—Ç—å—é –¥–æ—Å—Ç—É–ø–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
        print("üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –Ω–∞ GPU")
    elif nvidia_available and not pytorch_cuda_available:
        print("‚ö†Ô∏è  NVIDIA –¥—Ä–∞–π–≤–µ—Ä—ã –¥–æ—Å—Ç—É–ø–Ω—ã, –Ω–æ PyTorch CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        print("üîß –í–æ–∑–º–æ–∂–Ω–æ, –Ω—É–∂–Ω–æ –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å PyTorch —Å CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π")
    elif not nvidia_available and pytorch_cuda_available:
        print("‚ö†Ô∏è  PyTorch CUDA –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ nvidia-smi –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        print("üîß –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º–∞ —Å Docker GPU –ø—Ä–æ–±—Ä–æ—Å–æ–º")
    else:
        print("‚ùå GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        print("üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –Ω–∞ CPU (–º–µ–¥–ª–µ–Ω–Ω–æ)")
    
    print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    if not nvidia_available:
        print("- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ NVIDIA –¥—Ä–∞–π–≤–µ—Ä—ã —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
        print("- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ nvidia-docker2 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("- –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å —Ñ–ª–∞–≥–æ–º --gpus all")
    if not pytorch_cuda_available:
        print("- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch —Å CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π")
        print("- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π CUDA –∏ PyTorch")

if __name__ == "__main__":
    main()
